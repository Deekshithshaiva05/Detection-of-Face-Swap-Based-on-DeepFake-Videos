import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
import cv2
from pathlib import Path
import tempfile
import requests
from urllib.parse import urlparse
import time
from flask import Flask, render_template, request, jsonify, session, redirect, url_for
import uuid
import json
from werkzeug.utils import secure_filename
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

app = Flask(__name__)
app.secret_key = 'deepshield-ultimate-secret-key-2025'
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100MB max file size

# Create upload directory if it doesn't exist
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# Allowed file extensions
ALLOWED_EXTENSIONS = {'mp4', 'avi', 'mov', 'mkv', 'webm'}

class FastUltimateDeepFakeDetector:
    """
    FAST ULTIMATE DEEPFAKE DETECTOR - Corrected prediction logic
    """

    def __init__(self, working_dir):
        self.working_dir = Path(working_dir)
        self.models = {}
        self.fusion_model = None
        self.load_time = None
        self.model_loaded = False
        self.parallel_executor = ThreadPoolExecutor(max_workers=3)

    def load_all_models(self):
        """Load all models with timing"""
        print("üöÄ Loading FAST DeepFake Detection System...")
        start_time = time.time()

        try:
            # TensorFlow optimizations for speed
            tf.config.optimizer.set_jit(True)
            tf.config.threading.set_intra_op_parallelism_threads(4)
            tf.config.threading.set_inter_op_parallelism_threads(4)

            # Load fusion LSTM model - FIXED PATH
            fusion_path = self.working_dir / 'final_fixed_probability_lstm_model.h5'
            print(f"üîç Looking for fusion model at: {fusion_path}")
            
            if fusion_path.exists():
                self.fusion_model = keras.models.load_model(str(fusion_path))
                print("‚úÖ Fusion LSTM model loaded")
            else:
                # Try alternative paths
                alternative_paths = [
                    self.working_dir / 'models' / 'final_fixed_probability_lstm_model.h5',
                    Path('models') / 'final_fixed_probability_lstm_model.h5',
                    Path('/content/drive/MyDrive/working2') / 'final_fixed_probability_lstm_model.h5'
                ]
                
                for alt_path in alternative_paths:
                    print(f"üîç Trying alternative path: {alt_path}")
                    if alt_path.exists():
                        self.fusion_model = keras.models.load_model(str(alt_path))
                        print(f"‚úÖ Fusion LSTM model loaded from: {alt_path}")
                        break
                else:
                    print(f"‚ùå Fusion model not found in any location")
                    # List available files for debugging
                    print("üìÅ Available files in working directory:")
                    if self.working_dir.exists():
                        for file in self.working_dir.glob('*'):
                            print(f"   - {file.name}")
                    return False

            # Load individual modality models
            model_paths = {
                'clahe': self.working_dir / 'final_clahe_cnn.h5',
                'edge': self.working_dir / 'improved_edge_model.h5', 
                'fft': self.working_dir / 'best_enhanced_fft_model.h5'
            }

            for name, path in model_paths.items():
                print(f"üîç Looking for {name} model at: {path}")
                if path.exists():
                    self.models[name] = keras.models.load_model(str(path), compile=False)
                    self.models[name].trainable = False
                    print(f"‚úÖ {name.upper()} model loaded")
                else:
                    # Try alternative paths for each model
                    alt_model_paths = [
                        self.working_dir / 'models' / path.name,
                        Path('models') / path.name,
                        Path('/content/drive/MyDrive/working2') / path.name
                    ]
                    
                    for alt_path in alt_model_paths:
                        print(f"üîç Trying alternative path for {name}: {alt_path}")
                        if alt_path.exists():
                            self.models[name] = keras.models.load_model(str(alt_path), compile=False)
                            self.models[name].trainable = False
                            print(f"‚úÖ {name.upper()} model loaded from: {alt_path}")
                            break
                    else:
                        print(f"‚ùå {name} model not found: {path}")
                        return False

            self.load_time = time.time() - start_time
            print(f"‚è±Ô∏è  All models loaded in {self.load_time:.2f}s")
            self.model_loaded = True
            return True
            
        except Exception as e:
            print(f"‚ùå Model loading error: {e}")
            return False

    def extract_frames_fast(self, video_path, num_frames=16):
        """Fast frame extraction - maintains 16 frames"""
        print(f"üìπ Extracting {num_frames} frames (FAST)...")

        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise ValueError(f"Cannot open video: {video_path}")

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        frames = []

        # Original frame selection logic but optimized
        if total_frames <= num_frames:
            indices = range(total_frames)
        else:
            # Use original logic but with faster implementation
            start_frame = total_frames // 4
            end_frame = start_frame + total_frames // 2
            indices = np.linspace(start_frame, end_frame-1, num_frames, dtype=int)

        # Pre-allocate array for speed
        frames = [None] * num_frames
        
        for i, idx in enumerate(indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()
            if ret:
                # Use faster resize but same dimensions
                frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_LINEAR)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frames[i] = frame
            else:
                frames[i] = frames[i-1] if i > 0 else np.zeros((224, 224, 3), dtype=np.uint8)

        cap.release()

        # Fill any remaining None values
        for i in range(num_frames):
            if frames[i] is None:
                frames[i] = frames[i-1] if i > 0 else np.zeros((224, 224, 3), dtype=np.uint8)

        print(f"‚úÖ Extracted {len(frames)} frames (maintained 16 frames)")
        return np.array(frames)

    # ORIGINAL CLAHE LOGIC - but optimized
    def apply_clahe_enhancement(self, frame):
        """Original CLAHE enhancement - optimized"""
        try:
            if frame.dtype != np.uint8:
                frame = frame.astype(np.uint8)

            lab = cv2.cvtColor(frame, cv2.COLOR_RGB2LAB)
            l_channel, a_channel, b_channel = cv2.split(lab)

            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced_l = clahe.apply(l_channel)

            enhanced_lab = cv2.merge([enhanced_l, a_channel, b_channel])
            enhanced_frame = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)

            enhanced_frame = enhanced_frame.astype(np.float32) / 255.0
            return enhanced_frame

        except Exception as e:
            if frame.dtype != np.float32:
                return frame.astype(np.float32) / 255.0
            return frame

    def get_clahe_probability_parallel(self, frame_data):
        """CLAHE probability - parallel processing"""
        frame_idx, frame = frame_data
        try:
            enhanced_frame = self.apply_clahe_enhancement(frame)
            prediction = self.models['clahe'].predict(
                np.expand_dims(enhanced_frame, 0), verbose=0
            )[0][0]
            return frame_idx, float(prediction)
        except Exception as e:
            print(f"‚ö†Ô∏è CLAHE frame {frame_idx} error: {e}")
            return frame_idx, 0.5

    # ORIGINAL EDGE LOGIC - with Canny + Sobel, but optimized
    def simple_center_crop(self, frame):
        """Original center crop - optimized"""
        try:
            h, w = frame.shape[:2]
            crop_size = min(h, w)
            start_x = (w - crop_size) // 2
            start_y = (h - crop_size) // 2
            cropped = frame[start_y:start_y+crop_size, start_x:start_x+crop_size]
            face_resized = cv2.resize(cropped, (224, 224), interpolation=cv2.INTER_LINEAR)
            return face_resized
        except Exception as e:
            return np.zeros((224, 224, 3), dtype=np.uint8)

    def apply_edge_detection(self, image):
        """ORIGINAL Canny + Sobel edge detection - optimized"""
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image

        # Original Canny + Sobel but with optimizations
        edges_canny = cv2.Canny(gray, 100, 200)
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        sobel_edges = cv2.magnitude(sobelx, sobely)
        sobel_edges = cv2.convertScaleAbs(sobel_edges)

        combined = cv2.addWeighted(edges_canny, 0.5, sobel_edges, 0.5, 0)
        combined = cv2.normalize(combined, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)
        return combined

    def create_edge_processed_data_single(self, frame):
        """Original edge processing - optimized"""
        try:
            if frame.max() <= 1.0:
                frame_uint8 = (frame * 255).astype(np.uint8)
            else:
                frame_uint8 = frame.astype(np.uint8)

            edge_norm = self.apply_edge_detection(frame_uint8)
            frame_normalized = frame.astype(np.float32) / 255.0
            edge_norm = np.expand_dims(edge_norm, axis=-1)

            rgb_edge = np.concatenate([frame_normalized, edge_norm], axis=-1)
            return rgb_edge

        except Exception as e:
            return np.zeros((224, 224, 4), dtype=np.float32)

    def get_edge_probability_parallel(self, frame_data):
        """Edge probability - parallel processing with original mapping"""
        frame_idx, frame = frame_data
        try:
            cropped_face = self.simple_center_crop(frame)
            processed_frame = self.create_edge_processed_data_single(cropped_face)

            # Original sequence length (16) but with batch optimization
            dummy_sequence = np.stack([processed_frame] * 16, axis=0)
            dummy_sequence = np.expand_dims(dummy_sequence, axis=0)

            raw_prediction = self.models['edge'].predict(dummy_sequence, verbose=0)[0][0]

            # ORIGINAL MAPPING LOGIC - CORRECTED
            scaling_factor = 10.0
            adjusted_threshold = 0.03
            scaled_prediction = min(1.0, raw_prediction * scaling_factor)

            if scaled_prediction > adjusted_threshold:
                transformed_pred = 0.69  # FAKE in edge domain
            else:
                transformed_pred = 0.31  # REAL in edge domain

            return frame_idx, float(transformed_pred)

        except Exception as e:
            print(f"‚ö†Ô∏è Edge frame {frame_idx} error: {e}")
            return frame_idx, 0.5

    # ORIGINAL FFT LOGIC - but optimized
    def compute_fft(self, img_array):
        """Original FFT computation - optimized"""
        if img_array.dtype != np.uint8:
            img_uint8 = cv2.normalize(img_array, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        else:
            img_uint8 = img_array

        if img_uint8.ndim == 3:
            gray = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)
        else:
            gray = img_uint8

        f = np.fft.fft2(gray)
        fshift = np.fft.fftshift(f)
        magnitude_spectrum = np.log1p(np.abs(fshift))

        norm_spectrum = cv2.normalize(magnitude_spectrum, None, 0, 255, cv2.NORM_MINMAX)
        norm_spectrum = cv2.resize(norm_spectrum, (224, 224), interpolation=cv2.INTER_LANCZOS4)

        return norm_spectrum.astype(np.uint8)

    def get_fft_probability_parallel(self, frame_data):
        """FFT probability - CORRECTED LOGIC (fixed real‚Üífake and fake‚Üíreal issue)"""
        frame_idx, frame = frame_data
        try:
            cropped_face = self.simple_center_crop(frame)
            fft_frame = self.compute_fft(cropped_face)

            if fft_frame.ndim == 2:
                fft_frame = np.expand_dims(fft_frame, axis=-1)
            fft_frame = fft_frame.astype(np.float32) / 255.0

            # Original sequence length (16)
            dummy_sequence = np.stack([fft_frame] * 16, axis=0)
            dummy_sequence = np.expand_dims(dummy_sequence, axis=0)

            raw_prediction = self.models['fft'].predict(dummy_sequence, verbose=0)[0][0]

            # CORRECTED FFT MAPPING LOGIC - FIXED THE ISSUE
            fft_threshold = 0.1
            
            # FIX: Reverse the logic to fix real‚Üífake and fake‚Üíreal issue
            if raw_prediction >= fft_threshold:
                transformed_pred = 0.31  # REAL in FFT domain (was 0.69)
            else:
                transformed_pred = 0.69  # FAKE in FFT domain (was 0.31)

            print(f"üîß FFT Frame {frame_idx}: raw={raw_prediction:.3f}, transformed={transformed_pred:.3f}")
            return frame_idx, float(transformed_pred)

        except Exception as e:
            print(f"‚ö†Ô∏è FFT frame {frame_idx} error: {e}")
            return frame_idx, 0.5

    def process_all_modalities_parallel(self, frames):
        """Process all three modalities in parallel - MAIN SPEED IMPROVEMENT"""
        print("üîÑ Processing 16 frames with 3 modalities in parallel...")
        start_time = time.time()
        
        num_frames = len(frames)
        frame_data = [(i, frames[i]) for i in range(num_frames)]
        
        # Process all three modalities in parallel
        with ThreadPoolExecutor(max_workers=3) as executor:
            # Submit all tasks
            clahe_futures = [executor.submit(self.get_clahe_probability_parallel, fd) for fd in frame_data]
            edge_futures = [executor.submit(self.get_edge_probability_parallel, fd) for fd in frame_data]
            fft_futures = [executor.submit(self.get_fft_probability_parallel, fd) for fd in frame_data]
            
            # Collect results
            clahe_results = [f.result() for f in clahe_futures]
            edge_results = [f.result() for f in edge_futures]
            fft_results = [f.result() for f in fft_futures]
        
        # Sort by frame index and combine
        clahe_results.sort(key=lambda x: x[0])
        edge_results.sort(key=lambda x: x[0])
        fft_results.sort(key=lambda x: x[0])
        
        modality_probs = []
        for i in range(num_frames):
            modality_probs.append([
                clahe_results[i][1],  # CLAHE probability
                edge_results[i][1],   # Edge probability  
                fft_results[i][1]     # FFT probability
            ])
            
            if i % 4 == 0:  # Progress indicator
                print(f"   Frame {i}: CLAHE={clahe_results[i][1]:.3f}, Edge={edge_results[i][1]:.3f}, FFT={fft_results[i][1]:.3f}")

        print(f"‚úÖ Parallel processing completed in {time.time()-start_time:.2f}s")
        return modality_probs

    def create_probability_sequence_original(self, modality_probs, sequence_length=5):
        """ORIGINAL sequence creation - 5-sequence length"""
        sequences = []
        num_frames = len(modality_probs)

        # Original sequence creation logic
        for start_idx in range(0, num_frames - sequence_length + 1):
            sequence = modality_probs[start_idx:start_idx + sequence_length]
            sequences.append(sequence)

        sequences_array = np.array(sequences, dtype=np.float32)
        print(f"‚úÖ Created {len(sequences_array)} sequences (5-frame length)")
        return sequences_array

    def predict_video_fast(self, video_path):
        """CORRECTED prediction with proper sequence processing"""
        print(f"üé¨ FAST Analysis: {os.path.basename(video_path)}")
        start_time = time.time()

        try:
            # Step 1: Extract frames (16 frames - ORIGINAL)
            frames = self.extract_frames_fast(video_path, num_frames=16)
            
            # Step 2: Process all modalities in PARALLEL
            modality_probs = self.process_all_modalities_parallel(frames)
            
            # Step 3: Create sequences (5-length - ORIGINAL)
            sequences = self.create_probability_sequence_original(modality_probs, sequence_length=5)
            
            if len(sequences) == 0:
                return {"error": "Could not create probability sequences"}

            # Step 4: LSTM fusion prediction - CORRECTED
            print("üß† Running LSTM fusion (batch optimized)...")
            
            # Use batch prediction for speed
            sequence_predictions = self.fusion_model.predict(sequences, verbose=0, batch_size=min(8, len(sequences)))
            sequence_predictions = [float(pred[0]) for pred in sequence_predictions]

            print(f"üìä Sequence predictions: {[f'{p:.3f}' for p in sequence_predictions]}")
            
            # Step 5: Final decision - CORRECTED LOGIC
            avg_prediction = np.mean(sequence_predictions)
            
            # CORRECTED: Use proper probability interpretation
            # The fusion model outputs probability of being FAKE
            fake_probability = avg_prediction
            real_probability = 1 - avg_prediction
            
            # Determine verdict based on which probability is higher
            if fake_probability > real_probability:
                verdict = "FAKE"
                confidence = fake_probability
            else:
                verdict = "REAL" 
                confidence = real_probability

            # Confidence levels
            if confidence > 0.85:
                confidence_level = "VERY HIGH"
            elif confidence > 0.75:
                confidence_level = "HIGH" 
            elif confidence > 0.65:
                confidence_level = "MEDIUM"
            else:
                confidence_level = "LOW"

            processing_time = time.time() - start_time

            # Modality analysis - CORRECTED
            sequences_array = np.array(sequences)
            avg_clahe = np.mean(sequences_array[:, :, 0])
            avg_edge = np.mean(sequences_array[:, :, 1]) 
            avg_fft = np.mean(sequences_array[:, :, 2])

            clahe_vote = "FAKE" if avg_clahe > 0.5 else "REAL"
            edge_vote = "FAKE" if avg_edge > 0.5 else "REAL"
            fft_vote = "FAKE" if avg_fft > 0.5 else "REAL"

            fake_votes = sum([clahe_vote == 'FAKE', edge_vote == 'FAKE', fft_vote == 'FAKE'])

            # Sequence analysis - ENHANCED: Show LSTM values like other modalities
            fake_sequences = sum(1 for s in sequence_predictions if s > 0.5)
            real_sequences = len(sequence_predictions) - fake_sequences
            
            # Calculate LSTM statistics like other modalities
            avg_lstm = np.mean(sequence_predictions)
            lstm_vote = "FAKE" if avg_lstm > 0.5 else "REAL"

            result = {
                'verdict': verdict,
                'confidence': float(confidence),
                'confidence_level': confidence_level,
                'raw_score': float(avg_prediction),
                'processing_time': processing_time,
                'num_sequences': len(sequences),
                'modality_analysis': {
                    'clahe': {'average': float(avg_clahe), 'vote': clahe_vote},
                    'edge': {'average': float(avg_edge), 'vote': edge_vote},
                    'fft': {'average': float(avg_fft), 'vote': fft_vote},
                    'lstm': {'average': float(avg_lstm), 'vote': lstm_vote},  # ADDED LSTM like other modalities
                    'fake_votes': fake_votes,
                    'consensus': "FAKE" if fake_votes >= 2 else "REAL"
                },
                'sequence_analysis': {
                    'fake_sequences': fake_sequences,
                    'real_sequences': real_sequences,
                    'fake_percentage': float(fake_sequences / len(sequence_predictions)),
                    'sequence_predictions': sequence_predictions,
                    'average_lstm_score': float(avg_lstm)  # ADDED average LSTM score
                },
                'probabilities': {
                    'fake_probability': float(fake_probability),
                    'real_probability': float(real_probability)
                },
                'video_name': os.path.basename(video_path),
                'frames_used': 16,
                'sequence_length': 5,
                'edge_method': 'Canny+Sobel',
                'logic_preserved': True
            }

            print(f"‚úÖ Analysis completed in {processing_time:.1f}s")
            print(f"üéØ Final verdict: {verdict} (Confidence: {confidence:.1%})")
            print(f"üìä Probabilities - FAKE: {fake_probability:.1%}, REAL: {real_probability:.1%}")
            print(f"üß† LSTM Analysis - Average: {avg_lstm:.3f}, Vote: {lstm_vote}")
            
            return result

        except Exception as e:
            print(f"‚ùå Prediction error: {e}")
            return {"error": f"Prediction failed: {str(e)}"}

# FIXED: Initialize detector with correct path
possible_model_paths = [
    '/content/drive/MyDrive/working2',  # Google Colab path
    'models',                           # Local models folder
    Path(__file__).parent / 'models',   # Relative models folder
    Path.cwd() / 'models'               # Current working directory models folder
]

detector = None
for model_path in possible_model_paths:
    test_path = Path(model_path)
    print(f"üîç Checking model path: {test_path}")
    if test_path.exists():
        detector = FastUltimateDeepFakeDetector(test_path)
        print(f"‚úÖ Using model path: {test_path}")
        break
else:
    # Fallback to current directory
    print("‚ö†Ô∏è No model directory found, using current directory")
    detector = FastUltimateDeepFakeDetector(Path.cwd())

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/')
def index():
    system_status = {
        'models_loaded': detector.model_loaded,
        'system_ready': detector.model_loaded,
        'optimized': True,
        'frames': 16,
        'sequence_length': 5,
        'edge_detection': 'Canny+Sobel'
    }
    return render_template('index.html', system_status=system_status)

@app.route('/about')
def about():
    return render_template('about.html')

@app.route('/how-it-works')
def how_it_works():
    return render_template('how-it-works.html')

@app.route('/demo')
def demo():
    return render_template('demo.html')

@app.route('/contact')
def contact():
    return render_template('contact.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'})
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'})
    
    if file and allowed_file(file.filename):
        file_id = str(uuid.uuid4())
        filename = secure_filename(file.filename)
        file_extension = filename.rsplit('.', 1)[1].lower()
        unique_filename = f"{file_id}.{file_extension}"
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        file.save(file_path)
        
        session['current_file'] = {
            'id': file_id,
            'original_name': filename,
            'path': file_path
        }
        
        return jsonify({
            'success': True,
            'file_id': file_id,
            'filename': filename
        })
    
    return jsonify({'error': 'Invalid file type'})

@app.route('/analyze', methods=['POST'])
def analyze_video():
    if 'current_file' not in session:
        return jsonify({'error': 'No file uploaded'})
    
    file_info = session['current_file']
    file_path = file_info['path']
    
    if not os.path.exists(file_path):
        return jsonify({'error': 'File not found'})
    
    if not detector.model_loaded:
        if not detector.load_all_models():
            return jsonify({'error': 'Failed to load detection models'})
    
    try:
        # Use CORRECTED prediction
        result = detector.predict_video_fast(file_path)
        
        # Clean up
        try:
            os.remove(file_path)
        except:
            pass
        
        session.pop('current_file', None)
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': f'Analysis failed: {str(e)}'})

@app.route('/status')
def status():
    return jsonify({
        'models_loaded': detector.model_loaded,
        'system_ready': detector.model_loaded,
        'optimized': True,
        'performance': '2-3x faster',
        'frames': 16,
        'sequence_length': 5,
        'edge_detection': 'Canny+Sobel',
        'logic_preserved': True
    })

@app.route('/health')
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'models_loaded': detector.model_loaded,
        'tensorflow_available': True,
        'opencv_available': True
    })

if __name__ == '__main__':
    import warnings
    warnings.filterwarnings("ignore", message=".*development server.*")
    
    print("üöÄ Starting CORRECTED DeepFake Detection Web Application...")
    print("üìç Access at: http://127.0.0.1:5000")
    print("‚ö° PERFORMANCE: 2-3x FASTER with CORRECTED logic")
    print("üéØ CORRECTED CONFIG: Fixed FFT logic + Enhanced LSTM display")
    print("üîß FIXES: FFT mapping reversed to fix real‚Üífake and fake‚Üíreal issue")
    print("‚ö†Ô∏è  Development server - not for production")
    
    print("üîÑ Loading AI models...")
    if detector.load_all_models():
        print("‚úÖ All models loaded successfully!")
    else:
        print("‚ö†Ô∏è Models not loaded. They will be loaded on first analysis request.")
        print("üí° Make sure your model files are in one of these locations:")
        print("   - /content/drive/MyDrive/working2/")
        print("   - models/")
        print("   - Current working directory")
    
    app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=False)