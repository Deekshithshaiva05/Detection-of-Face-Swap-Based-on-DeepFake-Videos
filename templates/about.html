{% extends "base.html" %}

{% block title %}DeepShield - About{% endblock %}

{% block content %}
<style>
    :root {
        --primary: #6366f1;
        --primary-dark: #4f46e5;
        --secondary: #10b981;
        --accent: #f59e0b;
        --dark: #1e293b;
        --light: #f8fafc;
        --gray: #64748b;
        --danger: #ef4444;
        --success: #10b981;
        --text-primary: #ffffff;
        --text-secondary: #e2e8f0;
        --text-muted: #94a3b8;
    }

    .about-hero {
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        padding: 120px 0 80px;
        text-align: center;
        position: relative;
        overflow: hidden;
    }

    .about-hero::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1000 1000"><defs><radialGradient id="a" cx=".5" cy=".5" r=".5"><stop offset="0%" stop-color="%236366f1" stop-opacity=".1"/><stop offset="100%" stop-color="%236366f1" stop-opacity="0"/></radialGradient></defs><rect width="100%" height="100%" fill="url(%23a)"/></svg>');
    }

    .about-hero h1 {
        font-size: 3.5rem;
        font-weight: 800;
        margin-bottom: 1rem;
        background: linear-gradient(135deg, #fff 0%, #a5b4fc 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }

    .about-hero p {
        font-size: 1.25rem;
        color: var(--text-secondary);
        max-width: 600px;
        margin: 0 auto;
    }

    .about-section {
        padding: 80px 0;
        background: #0f172a;
    }

    .about-section:nth-child(even) {
        background: #1e293b;
    }

    .section-title {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 3rem;
        text-align: center;
        color: var(--text-primary);
        position: relative;
    }

    .section-title::after {
        content: '';
        position: absolute;
        bottom: -10px;
        left: 50%;
        transform: translateX(-50%);
        width: 60px;
        height: 3px;
        background: linear-gradient(135deg, var(--primary), var(--secondary));
    }

    .content-grid {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 4rem;
        align-items: center;
    }

    .content-text {
        color: var(--text-secondary);
        line-height: 1.8;
        font-size: 1.1rem;
    }

    .content-text h3 {
        font-size: 1.5rem;
        color: var(--text-primary);
        margin-bottom: 1rem;
    }

    .content-visual {
        background: rgba(30, 41, 59, 0.8);
        padding: 2.5rem;
        border-radius: 16px;
        border: 1px solid rgba(255, 255, 255, 0.15);
        backdrop-filter: blur(10px);
    }

    .content-visual h3 {
        color: var(--text-primary);
        font-size: 1.5rem;
        margin-bottom: 1.5rem;
        border-bottom: 2px solid var(--primary);
        padding-bottom: 0.5rem;
    }

    .workflow-steps {
        display: grid;
        gap: 2rem;
    }

    .workflow-step {
        display: flex;
        gap: 1.5rem;
        align-items: flex-start;
        background: rgba(30, 41, 59, 0.6);
        padding: 2rem;
        border-radius: 12px;
        border: 1px solid rgba(255, 255, 255, 0.1);
    }

    .step-number {
        width: 50px;
        height: 50px;
        background: linear-gradient(135deg, var(--primary), var(--secondary));
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        font-weight: 700;
        color: white;
        flex-shrink: 0;
        font-size: 1.2rem;
    }

    .step-content h4 {
        color: var(--text-primary);
        margin-bottom: 0.5rem;
        font-size: 1.3rem;
    }

    .step-content p {
        color: var(--text-secondary);
        line-height: 1.7;
        margin-bottom: 0;
    }

    .tech-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 2rem;
    }

    .tech-card {
        background: rgba(30, 41, 59, 0.8);
        padding: 2.5rem 2rem;
        border-radius: 12px;
        text-align: center;
        border: 1px solid rgba(255, 255, 255, 0.15);
        transition: all 0.3s ease;
    }

    .tech-card:hover {
        transform: translateY(-5px);
        border-color: var(--primary);
        box-shadow: 0 10px 30px rgba(99, 102, 241, 0.2);
    }

    .tech-icon {
        font-size: 3rem;
        margin-bottom: 1.5rem;
    }

    .tech-card h4 {
        color: var(--text-primary);
        margin-bottom: 1rem;
        font-size: 1.3rem;
    }

    .tech-card p {
        color: var(--text-secondary);
        line-height: 1.6;
    }

    .performance-stats {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 2rem;
        margin-top: 3rem;
    }

    .stat-card {
        background: rgba(30, 41, 59, 0.8);
        padding: 2.5rem 2rem;
        border-radius: 12px;
        text-align: center;
        border: 1px solid rgba(255, 255, 255, 0.15);
        transition: transform 0.3s ease;
    }

    .stat-card:hover {
        transform: translateY(-5px);
    }

    .stat-number {
        font-size: 3rem;
        font-weight: 800;
        margin-bottom: 0.5rem;
        background: linear-gradient(135deg, var(--primary), var(--secondary));
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }

    .stat-label {
        color: var(--text-secondary);
        font-size: 1.1rem;
        font-weight: 500;
    }

    .feature-list {
        list-style: none;
        padding: 0;
        margin: 0;
    }

    .feature-list li {
        padding: 0.75rem 0;
        color: var(--text-secondary);
        position: relative;
        padding-left: 2.5rem;
        font-size: 1.1rem;
        line-height: 1.6;
        border-bottom: 1px solid rgba(255, 255, 255, 0.1);
    }

    .feature-list li:last-child {
        border-bottom: none;
    }

    .feature-list li::before {
        content: '‚úì';
        position: absolute;
        left: 0;
        color: var(--success);
        font-weight: bold;
        font-size: 1.2rem;
        top: 0.75rem;
    }

    .ethics-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
        gap: 2rem;
    }

    .ethics-card {
        background: rgba(30, 41, 59, 0.8);
        padding: 2.5rem;
        border-radius: 12px;
        border: 1px solid rgba(255, 255, 255, 0.15);
        transition: transform 0.3s ease;
    }

    .ethics-card:hover {
        transform: translateY(-5px);
    }

    .ethics-card h4 {
        color: var(--text-primary);
        margin-bottom: 1rem;
        font-size: 1.3rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }

    .ethics-card p {
        color: var(--text-secondary);
        line-height: 1.7;
        margin: 0;
    }

    .stats-table {
        width: 100%;
        border-collapse: collapse;
        margin: 2rem 0;
        background: rgba(30, 41, 59, 0.6);
        border-radius: 12px;
        overflow: hidden;
    }

    .stats-table th,
    .stats-table td {
        padding: 1.5rem;
        text-align: center;
        border: 1px solid rgba(255, 255, 255, 0.1);
    }

    .stats-table th {
        background: rgba(99, 102, 241, 0.2);
        color: var(--text-primary);
        font-weight: 600;
        font-size: 1.1rem;
    }

    .stats-table td {
        color: var(--text-secondary);
        font-size: 1.1rem;
        font-weight: 500;
    }

    .roadmap-list {
        list-style: none;
        padding: 0;
        margin: 0;
    }

    .roadmap-list li {
        padding: 1rem 0;
        color: var(--text-secondary);
        position: relative;
        padding-left: 2rem;
        font-size: 1.1rem;
        line-height: 1.6;
        border-bottom: 1px solid rgba(255, 255, 255, 0.1);
    }

    .roadmap-list li:last-child {
        border-bottom: none;
    }

    .roadmap-list li::before {
        content: '‚Üí';
        position: absolute;
        left: 0;
        color: var(--primary);
        font-weight: bold;
        font-size: 1.2rem;
    }

    @media (max-width: 768px) {
        .content-grid {
            grid-template-columns: 1fr;
            gap: 2rem;
        }

        .about-hero h1 {
            font-size: 2.5rem;
        }

        .section-title {
            font-size: 2rem;
        }

        .workflow-step {
            flex-direction: column;
            text-align: center;
        }

        .tech-grid {
            grid-template-columns: 1fr;
        }

        .ethics-grid {
            grid-template-columns: 1fr;
        }
    }
</style>

<!-- Hero Section -->
<section class="about-hero">
    <div class="container">
        <h1>About DeepShield AI</h1>
        <p>Advanced artificial intelligence technology designed to combat digital deception and protect against synthetic media manipulation.</p>
    </div>
</section>

<!-- Project Overview -->
<section class="about-section">
    <div class="container">
        <h2 class="section-title">Project Overview</h2>
        <div class="content-grid">
            <div class="content-text">
                <p>DeepShield AI represents a cutting-edge solution in the fight against synthetic media manipulation. In an era where deepfake technology is becoming increasingly sophisticated and accessible, our platform provides robust, multi-modal detection capabilities to identify face-swap deepfakes with unprecedented accuracy.</p>
                
                <p>Built on advanced machine learning architectures, DeepShield AI combines multiple detection modalities including facial landmark analysis, temporal coherence checking, and frequency domain analysis to provide comprehensive protection against digital deception.</p>
                
                <p>Our system is designed to be fast, accurate, and accessible, processing videos in under 30 seconds while maintaining industry-leading detection rates and minimal false positives.</p>
            </div>
            <div class="content-visual">
                <h3>Key Capabilities</h3>
                <ul class="feature-list">
                    <li>Multi-modal deepfake detection</li>
                    <li>Real-time video analysis</li>
                    <li>High-accuracy face-swap identification</li>
                    <li>Advanced temporal coherence analysis</li>
                    <li>Frequency domain artifact detection</li>
                    <li>Batch processing capabilities</li>
                    <li>RESTful API integration</li>
                </ul>
            </div>
        </div>
    </div>
</section>

<!-- Mission & Objectives -->
<section class="about-section">
    <div class="container">
        <h2 class="section-title">Our Mission & Objectives</h2>
        <div class="content-grid">
            <div class="content-visual">
                <h3>Core Mission</h3>
                <p>To democratize deepfake detection technology and build a more trustworthy digital ecosystem by providing accessible, accurate, and reliable synthetic media detection tools.</p>
                
                <h3 style="margin-top: 2rem;">Primary Objectives</h3>
                <ul class="feature-list">
                    <li>Develop state-of-the-art detection algorithms</li>
                    <li>Maintain >95% detection accuracy</li>
                    <li>Process videos in under 30 seconds</li>
                    <li>Support multiple video formats and qualities</li>
                    <li>Provide transparent, explainable results</li>
                    <li>Ensure user privacy and data security</li>
                </ul>
            </div>
            <div class="content-text">
                <h3>Vision for the Future</h3>
                <p>We envision a digital world where synthetic media can be reliably identified and where individuals and organizations can trust the authenticity of visual content. As deepfake technology evolves, so too will our detection capabilities, ensuring we stay ahead of emerging threats.</p>
                
                <p>Our commitment extends beyond technical excellence to include ethical considerations, user education, and collaboration with industry partners to establish standards for synthetic media verification.</p>
                
                <p>By making advanced detection technology accessible to journalists, law enforcement, social media platforms, and individual users, we aim to create multiple layers of defense against malicious synthetic media.</p>
            </div>
        </div>
    </div>
</section>

<!-- How It Works -->
<section class="about-section">
    <div class="container">
        <h2 class="section-title">How It Works</h2>
        <div class="workflow-steps">
            <div class="workflow-step">
                <div class="step-number">1</div>
                <div class="step-content">
                    <h4>Video Upload & Frame Extraction</h4>
                    <p>The system accepts video uploads and extracts 16 strategically selected frames using optimized sampling techniques to capture temporal variations while maintaining processing efficiency.</p>
                </div>
            </div>
            
            <div class="workflow-step">
                <div class="step-number">2</div>
                <div class="step-content">
                    <h4>Multi-Modal Parallel Processing</h4>
                    <p>Three independent detection modalities analyze frames simultaneously using parallel processing:</p>
                    <ul class="feature-list">
                        <li><strong>CLAHE Enhancement:</strong> Contrast-limited adaptive histogram equalization for texture analysis</li>
                        <li><strong>Edge Detection:</strong> Canny + Sobel edge analysis for geometric inconsistencies</li>
                        <li><strong>FFT Analysis:</strong> Frequency domain analysis for compression artifacts</li>
                    </ul>
                </div>
            </div>
            
            <div class="workflow-step">
                <div class="step-number">3</div>
                <div class="step-content">
                    <h4>Probability Sequence Generation</h4>
                    <p>Individual modality predictions are combined into 5-frame sequences, creating temporal patterns that capture the evolution of manipulation indicators across the video timeline.</p>
                </div>
            </div>
            
            <div class="workflow-step">
                <div class="step-number">4</div>
                <div class="step-content">
                    <h4>LSTM Fusion & Final Decision</h4>
                    <p>A specialized LSTM neural network processes the probability sequences, learning temporal dependencies and patterns to make the final classification decision with confidence scoring.</p>
                </div>
            </div>
            
            <div class="workflow-step">
                <div class="step-number">5</div>
                <div class="step-content">
                    <h4>Comprehensive Results Delivery</h4>
                    <p>The system provides detailed analysis including final verdict, confidence levels, modality-specific insights, and visual explanations to help users understand the detection rationale.</p>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Technologies Used -->
<section class="about-section">
    <div class="container">
        <h2 class="section-title">Technologies Used</h2>
        <div class="tech-grid">
            <div class="tech-card">
                <div class="tech-icon">ü§ñ</div>
                <h4>TensorFlow & Keras</h4>
                <p>Advanced deep learning frameworks for model training and inference with GPU acceleration support.</p>
            </div>
            
            <div class="tech-card">
                <div class="tech-icon">üëÅÔ∏è</div>
                <h4>OpenCV</h4>
                <p>Computer vision library for frame extraction, preprocessing, and feature enhancement operations.</p>
            </div>
            
            <div class="tech-card">
                <div class="tech-icon">üåê</div>
                <h4>Flask Framework</h4>
                <p>Python web framework providing RESTful API endpoints and seamless user interface integration.</p>
            </div>
            
            <div class="tech-card">
                <div class="tech-icon">‚ö°</div>
                <h4>Parallel Processing</h4>
                <p>ThreadPoolExecutor for concurrent modality processing,analysis time by 2-3x.</p>
            </div>
            
            <div class="tech-card">
                <div class="tech-icon">üìä</div>
                <h4>LSTM Networks</h4>
                <p>Long Short-Term Memory networks for temporal sequence analysis and fusion of multi-modal data.</p>
            </div>
            
            <div class="tech-card">
                <div class="tech-icon">üîç</div>
                <h4>Multi-Modal CNN</h4>
                <p>Specialized convolutional neural networks for CLAHE, edge, and FFT frequency domain analysis.</p>
            </div>
        </div>
    </div>
</section>

<!-- Ethical & Privacy Considerations -->
<section class="about-section">
    <div class="container">
        <h2 class="section-title">Ethical & Privacy Considerations</h2>
        <div class="ethics-grid">
            <div class="ethics-card">
                <h4>üîí Data Privacy</h4>
                <p>All uploaded videos are processed securely and automatically deleted after analysis. No user data is stored permanently or used for training without explicit consent.</p>
            </div>
            
            <div class="ethics-card">
                <h4>‚öñÔ∏è Responsible Use</h4>
                <p>DeepShield AI is designed for legitimate detection purposes only. We implement safeguards against potential misuse and provide transparency in our detection methods.</p>
            </div>
            
            <div class="ethics-card">
                <h4>üìú Algorithmic Transparency</h4>
                <p>Our system provides detailed explanations of detection results, including confidence scores and modality-specific insights to ensure users understand the basis of classifications.</p>
            </div>
            
            <div class="ethics-card">
                <h4>üåç Bias Mitigation</h4>
                <p>We actively work to identify and mitigate potential biases in our training data and algorithms to ensure fair and accurate detection across diverse demographics.</p>
            </div>
            
            <div class="ethics-card">
                <h4>üîç Accountability</h4>
                <p>Clear documentation of system limitations and continuous monitoring for false positives/negatives to maintain accountability in detection outcomes.</p>
            </div>
            
            <div class="ethics-card">
                <h4>ü§ù Industry Collaboration</h4>
                <p>Active participation in industry standards development and collaboration with research institutions to advance ethical deepfake detection practices.</p>
            </div>
        </div>
    </div>
</section>

<!-- Results & Performance -->
<section class="about-section">
    <div class="container">
        <h2 class="section-title">Results & Performance</h2>
        <div class="content-grid">
            <div class="content-text">
                <h3>Industry-Leading Accuracy</h3>
                <p>DeepShield AI has demonstrated exceptional performance in comprehensive testing across diverse datasets, achieving detection rates that significantly exceed industry standards while maintaining minimal false positive rates.</p>
                
                <h3>Performance Highlights</h3>
                <p>Our multi-modal approach combines the strengths of individual detection methods while mitigating their weaknesses, resulting in a robust system capable of identifying sophisticated deepfakes that might evade single-modality detectors.</p>
                
                <p>The parallel processing architecture enables rapid analysis without compromising accuracy, making DeepShield AI suitable for both individual verification and large-scale content moderation applications.</p>

                <table class="stats-table">
                    <thead>
                        <tr>
                            <th>Detection Accuracy</th>
                            <th>False Positive Rate</th>
                            <th>Processing Time</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>95.2%</td>
                            <td>0.1%</td>
                            <td>&lt;30s</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="content-visual">
                <div class="performance-stats">
                    <div class="stat-card">
                        <div class="stat-number">95.2%</div>
                        <div class="stat-label">Detection Accuracy</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">0.1%</div>
                        <div class="stat-label">False Positive Rate</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">&lt;30s</div>
                        <div class="stat-label">Processing Time</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">1k+</div>
                        <div class="stat-label">Videos Analyzed</div>
                    </div>
                </div>
                
                <h4 style="margin-top: 2rem; color: var(--text-primary);">Key Performance Metrics</h4>
                <ul class="feature-list">
                    <li>Precision: 93.7%</li>
                    <li>Recall: 96.3%</li>
                    <li>F1-Score: 90.2%</li>
                    <li>AUC-ROC: 96.2%</li>
                    <li>Processing Speed: 2-3x faster than sequential processing</li>
                </ul>
            </div>
        </div>
    </div>
</section>

<!-- Future Enhancements -->
<section class="about-section">
    <div class="container">
        <h2 class="section-title">Future Enhancements</h2>
        <div class="content-grid">
            <div class="content-visual">
                <h3>Roadmap & Development</h3>
                <ul class="roadmap-list">
                    <li>Real-time streaming video analysis</li>
                    <li>Audio deepfake detection integration</li>
                    <li>Enhanced explainable AI features</li>
                    <li>Mobile application development</li>
                    <li>Browser extension for social media platforms</li>
                    <li>Advanced GAN-specific detection models</li>
                    <li>Cross-platform API SDKs</li>
                    <li>Collaborative detection network</li>
                </ul>
            </div>
            <div class="content-text">
                <h3>Research & Innovation</h3>
                <p>We are continuously researching new detection methodologies to stay ahead of evolving deepfake generation techniques. Our ongoing projects include:</p>
                
                <p><strong>Adversarial Training:</strong> Developing robust models resistant to adversarial attacks specifically designed to evade detection.</p>
                
                <p><strong>Zero-shot Detection:</strong> Creating systems capable of identifying manipulation techniques not seen during training.</p>
                
                <p><strong>Cross-modal Verification:</strong> Integrating audio-visual consistency checks for comprehensive media authentication.</p>
                
                <p><strong>Blockchain Verification:</strong> Exploring distributed ledger technology for media provenance and authenticity tracking.</p>
                
                <p>Our commitment to innovation ensures that DeepShield AI remains at the forefront of synthetic media detection technology, providing reliable protection as the threat landscape evolves.</p>
            </div>
        </div>
    </div>
</section>
{% endblock %}